{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "designed-profession",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.8.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import *\n",
    "from PIL import ImageTk, Image\n",
    "import cv2\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "import tensorflow as tf      \n",
    "import random\n",
    "from google_trans_new import google_translator  \n",
    "translator = google_translator()  \n",
    "from gtts import gTTS #Import Google Text to Speech\n",
    "from IPython.display import Audio \n",
    "import pygame\n",
    "pygame.mixer.init()\n",
    "from PIL import Image,ImageDraw,ImageFont,ImageTk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "everyday-sheriff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#load the trained model to classify sign\n",
    "from keras.models import load_model\n",
    "model1 = load_model('sl_keras_model.h5')\n",
    "model2 = load_model('char_model.h5')\n",
    "model3 = load_model('model_digit.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "continuous-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "top=tk.Tk()\n",
    "top.geometry('800x600')\n",
    "top.title('Multitudinous Object Detection')\n",
    "image1 = Image.open(\"C:\\\\Users\\\\kalas\\\\Downloads\\\\wallpaper_edi.jpg\")\n",
    "test = ImageTk.PhotoImage(image1)\n",
    "\n",
    "label1 = tk.Label(image=test)\n",
    "label1.image = test\n",
    "\n",
    "# Position image\n",
    "label1.place(x=1, y=1)\n",
    "\n",
    "\n",
    "#top.configure(background=C:\\\\Users\\\\kalas\\\\Downloads\\\\1124103.jpg)\n",
    "#top['bg']='RoyalBlue3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "steady-vessel",
   "metadata": {},
   "outputs": [],
   "source": [
    "label=Label(top,background='darkblue' ,font=('arial',50,'bold'))\n",
    "sign_image = Label(top,background='black',font=('arial',50,'bold'))\n",
    "#image1 = Image.open('C:\\\\Users\\\\kalas\\\\Downloads\\\\1124103.jpg')\n",
    "#test = ImageTk.PhotoImage(image1)\n",
    "\n",
    "#label = tk.Label(image=test)\n",
    "#sign_image = Label(top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smaller-wichita",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign_lang(file_path):\n",
    "    global label_packed\n",
    "    image = cv2.imread(file_path)\n",
    "    def predict(model1, img):\n",
    "        x = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        preds = model1.predict(x)\n",
    "        max_sl=preds.max()\n",
    "        print(max_sl)\n",
    "        return preds[0]\n",
    "\n",
    "    dim=(224,224)\n",
    "    img=cv2.resize(image,dim)\n",
    "    preds = predict(model1, image)\n",
    "\n",
    "    Gesture = np.argmax(preds)\n",
    "    dict = {0:'A', 1:'B', 2:'C' , 3:'D', 4:'E', 5:'F', 6:'G', 7:'H', 8:'I', 9:'J', 10:'K', 11:'L', 12:'M', 13:'N', 14:'O', 15:'P', 16:'Q', 17:'R', 18:'S', 19:'T', 20:'U', 21:'V', 22:'W', 23:'X', 24:'Y', 25:'Z', 26:'del', 27:'nothing', 28:'space'}\n",
    "\n",
    "    output = 'The gesture made by Hand Represents alphabet: ' + dict[Gesture]                   \n",
    "    print(preds)\n",
    "\n",
    "   \n",
    "    label.configure(foreground='white', text=dict[Gesture],font=('arial',50,'bold')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fourth-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def char(file_path):\n",
    "    global label_packed\n",
    "    img = cv2.imread(file_path)\n",
    "    img_copy = img.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (400,440))\n",
    "\n",
    "    img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)\n",
    "    img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "    img_final = cv2.resize(img_thresh, (28,28))\n",
    "    img_final =np.reshape(img_final, (1,28,28,1))\n",
    "    word_dict = {0:'A',1:'B',2:'C',3:'D',4:'E',5:'F',6:'G',7:'H',8:'I',9:'J',10:'K',11:'L',12:'M',13:'N',14:'O',15:'P',16:'Q',17:'R',18:'S',19:'T',20:'U',21:'V',22:'W',23:'X', 24:'Y',25:'Z'}\n",
    "\n",
    "    img_pred = word_dict[np.argmax(model2.predict(img_final))]\n",
    "    max_char=model2.predict(img_final).max()\n",
    "    print(model2.predict(img_final))\n",
    "    print('The Character alphabet is: ' + img_pred)\n",
    "    r1 = random.randint(1,10000000)\n",
    "    r2 = random.randint(1,10000000)\n",
    "    sound_file = str(r2)+\"Character\"+str(r1) +\".mp3\"\n",
    "    \n",
    "    tts = gTTS(img_pred) #Provide the string to convert to speech\n",
    "    tts.save(sound_file)\n",
    "    Audio(sound_file, autoplay=False)\n",
    "    label.configure(foreground='white', text=img_pred,font=('arial',50,'bold')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compatible-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def digit(file_path):\n",
    "    global label_packed\n",
    "    img = cv2.imread(file_path)\n",
    "    img_copy = img.copy()\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "\n",
    "    img_copy = cv2.GaussianBlur(img_copy, (7,7), 0)\n",
    "    img_gray = cv2.cvtColor(img_copy, cv2.COLOR_BGR2GRAY)\n",
    "    _, img_thresh = cv2.threshold(img_gray, 100, 255, cv2.THRESH_BINARY_INV)\n",
    "    img_final = cv2.resize(img_thresh, (28,28))\n",
    "    img_final =np.reshape(img_final, (1,28,28,1))\n",
    "\n",
    "    word_dict = {0:'0',1:'1',2:'2',3:'3',4:'4',5:'5',6:'6',7:'7',8:'8',9:'9'}\n",
    "    #img_pred = model3.predict(img_final)\n",
    "    \n",
    "    img_pred = word_dict[np.argmax(model3.predict(img_final))]\n",
    "    r1 = random.randint(1,10000000)\n",
    "    r2 = random.randint(1,10000000)\n",
    "    sound_file = str(r2)+\"Digit\"+str(r1) +\".mp3\"\n",
    "    \n",
    "    tts = gTTS(img_pred) #Provide the string to convert to speech\n",
    "    tts.save(sound_file)\n",
    "    Audio(sound_file, autoplay=True)\n",
    "    \n",
    "    print(img_pred)\n",
    "    label.configure(foreground='white', text=img_pred,font=('arial',50,'bold')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sustainable-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classify_button_sl(file_path):\n",
    "    classify_b=Button(top,text=\"Classify Sign Language\",command=lambda: sign_lang(file_path),padx=10,pady=5)\n",
    "    classify_b.configure(background='#364156', foreground='white',font=(\"TimesNewRoman\", 14))\n",
    "    classify_b.place(relx=0.79,rely=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aquatic-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classify_button_dig(file_path):\n",
    "    classify_d=Button(top,text=\"    Classify Digit     \",command=lambda: digit(file_path),padx=10,pady=5)\n",
    "    classify_d.configure(background='#364156', foreground='white',font=(\"TimesNewRoman\", 14))\n",
    "    classify_d.place(relx=0.79,rely=0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "coupled-gossip",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_classify_button_char(file_path):\n",
    "    classify_c=Button(top,text=\"   Classify Character  \",command=lambda: char(file_path),padx=10,pady=5)\n",
    "    classify_c.configure(background='#364156', foreground='white',font=(\"TimesNewRoman\", 14))\n",
    "    classify_c.place(relx=0.79,rely=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rising-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_image():\n",
    "    try:\n",
    "        file_path=filedialog.askopenfilename()\n",
    "        uploaded=Image.open(file_path)\n",
    "        uploaded.thumbnail(((top.winfo_width()/3),(top.winfo_height()/3)))\n",
    "        im=ImageTk.PhotoImage(uploaded)\n",
    "        #im = im.resize((200, 200), Image.ANTIALIAS)\n",
    "        sign_image.configure(image=im)\n",
    "        sign_image.image=im\n",
    "        label.configure(text='')\n",
    "        show_classify_button_sl(file_path)\n",
    "        show_classify_button_char(file_path)\n",
    "        show_classify_button_dig(file_path)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abandoned-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "upload=Button(top,text=\"Upload an image\",command=upload_image,padx=10,pady=5)\n",
    "upload.configure(background='#364156', foreground='white',font=('arial',10,'bold'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "sharing-reservoir",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "upload.pack(side=BOTTOM,pady=50)\n",
    "sign_image.pack(side=BOTTOM,expand=False)\n",
    "label.pack(side=BOTTOM,expand=True)\n",
    "#heading = Label(top, text=\"Multitudinous Object Detection\",pady=20, font=('TimesNewRoman',50,'bold'))\n",
    "#heading.configure(background='#CDCDCD',foreground='#364156')\n",
    "label3 = Label(top,text=' Multitudinous Object Detection ',bg='lavender',font=('TimesNewRoman',32,'bold'),borderwidth=3,relief='solid')\n",
    "label3.place(x=470,y=40)\n",
    "#heading.pack()\n",
    "top.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distributed-faculty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-heritage",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ancient-thesaurus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-lodge",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "small-interstate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-bookmark",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
